{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T16:24:17.042068Z",
     "iopub.status.busy": "2025-04-05T16:24:17.041740Z",
     "iopub.status.idle": "2025-04-05T16:24:25.520263Z",
     "shell.execute_reply": "2025-04-05T16:24:25.519420Z",
     "shell.execute_reply.started": "2025-04-05T16:24:17.042042Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pennylane\n",
      "  Downloading PennyLane-0.40.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.2)\n",
      "Collecting rustworkx>=0.14.0 (from pennylane)\n",
      "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
      "Collecting tomlkit (from pennylane)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting appdirs (from pennylane)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting autoray>=0.6.11 (from pennylane)\n",
      "  Downloading autoray-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
      "Collecting pennylane-lightning>=0.40 (from pennylane)\n",
      "  Downloading PennyLane_Lightning-0.40.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.2)\n",
      "Collecting diastatic-malt (from pennylane)\n",
      "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.1->pennylane) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.1->pennylane) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.1->pennylane) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.1->pennylane) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.1->pennylane) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.1->pennylane) (2.4.1)\n",
      "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.40->pennylane)\n",
      "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.10/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
      "Requirement already satisfied: gast in /usr/local/lib/python3.10/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from diastatic-malt->pennylane) (2.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2025.1.31)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.1->pennylane) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.1->pennylane) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.1->pennylane) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.1->pennylane) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.1->pennylane) (2024.2.0)\n",
      "Downloading PennyLane-0.40.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading autoray-0.7.1-py3-none-any.whl (930 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PennyLane_Lightning-0.40.0-cp310-cp310-manylinux_2_28_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: appdirs, tomlkit, scipy-openblas32, autoray, diastatic-malt, rustworkx, pennylane-lightning, pennylane\n",
      "Successfully installed appdirs-1.4.4 autoray-0.7.1 diastatic-malt-2.15.2 pennylane-0.40.0 pennylane-lightning-0.40.0 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pennylane as qml\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Dataset class\n",
    "class HAM10000Dataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform if transform else transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image.float().to(device), torch.tensor(label, dtype=torch.long, device=device)\n",
    "\n",
    "# Define transforms with data augmentation\n",
    "def get_optimized_transforms():\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # Reduced size for faster training\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # Reduced size for faster training\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regular CNN model - simplified for better generalization\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Calculate size after pooling operations\n",
    "        # 128 -> 64 -> 32 -> 16\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quantum_circuit(n_qubits, n_layers):\n",
    "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "    \n",
    "    @qml.qnode(dev)\n",
    "    def quantum_circuit(inputs, weights):\n",
    "        # Angle encoding\n",
    "        for i in range(n_qubits):\n",
    "            qml.RY(inputs[i], wires=i)\n",
    "        \n",
    "        # Variational layers\n",
    "        for l in range(n_layers):\n",
    "            # Rotation gates with learned parameters\n",
    "            for i in range(n_qubits):\n",
    "                qml.RY(weights[l][i][0], wires=i)\n",
    "                qml.RZ(weights[l][i][1], wires=i)\n",
    "            \n",
    "            # Entanglement\n",
    "            for i in range(n_qubits - 1):\n",
    "                qml.CZ(wires=[i, i + 1])\n",
    "            \n",
    "            if n_qubits > 1:\n",
    "                qml.CZ(wires=[n_qubits - 1, 0])  # Connect last qubit to first\n",
    "        \n",
    "        # Measurement in computational basis\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "    \n",
    "    return quantum_circuit\n",
    "\n",
    "# Define improved hybrid quantum-classical model\n",
    "class HybridQuantumCNN(nn.Module):\n",
    "    def __init__(self, n_qubits=6, n_qlayers=2, num_classes=7):\n",
    "        super(HybridQuantumCNN, self).__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_qlayers = n_qlayers\n",
    "        \n",
    "        # Classical CNN part - simplified\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully connected to reduce dimensions\n",
    "        # 128 -> 64 -> 32\n",
    "        self.fc_reduce = nn.Linear(32 * 32 * 32, n_qubits)\n",
    "        \n",
    "        # Quantum circuit\n",
    "        self.quantum_circuit = create_quantum_circuit(n_qubits, n_qlayers)\n",
    "        \n",
    "        # Initialize quantum weights - more expressive parameterization\n",
    "        weight_shapes = {\"weights\": (n_qlayers, n_qubits, 2)}  # 2 parameters per qubit per layer\n",
    "        self.qlayer = qml.qnn.TorchLayer(self.quantum_circuit, weight_shapes)\n",
    "        \n",
    "        # Classical output layers with better capacity\n",
    "        self.fc_hidden = nn.Linear(n_qubits, 32)\n",
    "        self.fc_output = nn.Linear(32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Classical CNN feature extraction\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Reduce to quantum input dimension\n",
    "        x = F.leaky_relu(self.fc_reduce(x))  # Use LeakyReLU for better gradients\n",
    "        x = torch.tanh(x) * np.pi  # Scale to [-π, π] for rotation gates\n",
    "        \n",
    "        # Process batch through quantum circuit\n",
    "        batch_size = x.shape[0]\n",
    "        q_out = torch.zeros(batch_size, self.n_qubits, device=x.device)\n",
    "        \n",
    "        # Process in smaller batches to avoid memory issues with quantum circuit\n",
    "        for i in range(batch_size):\n",
    "            q_out[i] = self.qlayer(x[i])\n",
    "        \n",
    "        # Final classification layers\n",
    "        x = F.relu(self.fc_hidden(q_out))\n",
    "        x = self.fc_output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "                num_epochs=10, model_name=\"model\", patience=5, clip_value=1.0):\n",
    "    best_val_acc = 0.0\n",
    "    best_val_f1 = 0.0\n",
    "    patience_counter = 0\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "        'val_loss': [], 'val_acc': [], 'val_f1': []\n",
    "    }\n",
    "    \n",
    "    print(f\"Starting training {model_name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_train_preds = []\n",
    "        all_train_labels = []\n",
    "        \n",
    "        train_loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for inputs, labels in train_loop:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Collect for metrics\n",
    "            all_train_preds.extend(predicted.cpu().numpy())\n",
    "            all_train_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar with current batch loss\n",
    "            train_loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = accuracy_score(all_train_labels, all_train_preds)\n",
    "        epoch_train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['train_f1'].append(epoch_train_f1)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_val_preds = []\n",
    "        all_val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_loop = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')\n",
    "            for inputs, labels in val_loop:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                # Collect for metrics\n",
    "                all_val_preds.extend(predicted.cpu().numpy())\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # Update progress bar with current batch loss\n",
    "                val_loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = accuracy_score(all_val_labels, all_val_preds)\n",
    "        epoch_val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        history['val_f1'].append(epoch_val_f1)\n",
    "        \n",
    "        # Print per-class metrics for validation\n",
    "        class_names = ['nv', 'mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df']\n",
    "        val_f1_per_class = f1_score(all_val_labels, all_val_preds, average=None, zero_division=0)\n",
    "        print(f'\\nValidation F1 scores by class:')\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            print(f'{class_name}: {val_f1_per_class[i]:.4f}', end=' | ')\n",
    "        print()\n",
    "        \n",
    "        # Check distribution of predictions\n",
    "        pred_counts = Counter(all_val_preds)\n",
    "        print(f'Prediction distribution: {dict(pred_counts)}')\n",
    "        \n",
    "        # Step the scheduler\n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(epoch_val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}, Train F1: {epoch_train_f1:.4f}, '\n",
    "              f'Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}, Val F1: {epoch_val_f1:.4f}')\n",
    "        \n",
    "        # Save best model based on F1 score (better for imbalanced data)\n",
    "        if epoch_val_f1 > best_val_f1:\n",
    "            best_val_f1 = epoch_val_f1\n",
    "            best_val_acc = epoch_val_acc\n",
    "            torch.save(model.state_dict(), f'{model_name}_best.pth')\n",
    "            print(f'Saved new best model with validation F1: {best_val_f1:.4f}, Acc: {best_val_acc:.4f}')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f'Validation F1 did not improve. Patience: {patience_counter}/{patience}')\n",
    "            \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "            break\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f'Training completed in {total_time/60:.2f} minutes')\n",
    "    print(f'Best validation F1: {best_val_f1:.4f}, Accuracy: {best_val_acc:.4f}')\n",
    "    \n",
    "    # Load best model for return\n",
    "    model.load_state_dict(torch.load(f'{model_name}_best.pth'))\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, model_name=\"model\", class_names=None):\n",
    "    if class_names is None:\n",
    "        class_names = ['nv', 'mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df']\n",
    "        \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []  # Store probabilities for ROC analysis\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=f'Evaluating {model_name}'):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics with zero_division parameter to avoid warnings\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_norm = np.nan_to_num(cm_norm)  # Replace NaN with zero\n",
    "    \n",
    "    # Per-class metrics\n",
    "    per_class_precision = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "    per_class_recall = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "    per_class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "    \n",
    "    # Print results\n",
    "    print(f'\\nTest Results for {model_name}:')\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    \n",
    "    # Check prediction distribution\n",
    "    pred_counts = Counter(all_preds)\n",
    "    print(f'Prediction distribution: {dict(pred_counts)}')\n",
    "    \n",
    "    print('\\nPer-class metrics:')\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f'{class_name}: Precision={per_class_precision[i]:.4f}, '\n",
    "              f'Recall={per_class_recall[i]:.4f}, '\n",
    "              f'F1={per_class_f1[i]:.4f}')\n",
    "    \n",
    "    # Plot confusion matrix with percentages\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Normalized Confusion Matrix - {model_name}')\n",
    "    plt.savefig(f'{model_name}_confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Also plot raw counts\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix (Counts) - {model_name}')\n",
    "    plt.savefig(f'{model_name}_confusion_matrix_counts.png')\n",
    "    plt.close()\n",
    "    \n",
    "    results = {\n",
    "        'loss': test_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'per_class_precision': per_class_precision,\n",
    "        'per_class_recall': per_class_recall,\n",
    "        'per_class_f1': per_class_f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'confusion_matrix_norm': cm_norm,\n",
    "        'all_probs': np.array(all_probs),\n",
    "        'all_preds': np.array(all_preds),\n",
    "        'all_labels': np.array(all_labels)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Improved comparison function\n",
    "def compare_models(simple_history, hybrid_history, simple_results, hybrid_results, class_names=None):\n",
    "    if class_names is None:\n",
    "        class_names = ['nv', 'mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df']\n",
    "        \n",
    "    # Plot training and validation metrics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(simple_history['train_loss'], label='Simple CNN - Train')\n",
    "    axes[0, 0].plot(simple_history['val_loss'], label='Simple CNN - Val')\n",
    "    axes[0, 0].plot(hybrid_history['train_loss'], label='Hybrid Quantum CNN - Train')\n",
    "    axes[0, 0].plot(hybrid_history['val_loss'], label='Hybrid Quantum CNN - Val')\n",
    "    axes[0, 0].set_title('Loss Comparison')\n",
    "    axes[0, 0].set_xlabel('Epochs')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(simple_history['train_acc'], label='Simple CNN - Train')\n",
    "    axes[0, 1].plot(simple_history['val_acc'], label='Simple CNN - Val')\n",
    "    axes[0, 1].plot(hybrid_history['train_acc'], label='Hybrid Quantum CNN - Train')\n",
    "    axes[0, 1].plot(hybrid_history['val_acc'], label='Hybrid Quantum CNN - Val')\n",
    "    axes[0, 1].set_title('Accuracy Comparison')\n",
    "    axes[0, 1].set_xlabel('Epochs')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # F1 Score\n",
    "    axes[1, 0].plot(simple_history['train_f1'], label='Simple CNN - Train')\n",
    "    axes[1, 0].plot(simple_history['val_f1'], label='Simple CNN - Val')\n",
    "    axes[1, 0].plot(hybrid_history['train_f1'], label='Hybrid Quantum CNN - Train')\n",
    "    axes[1, 0].plot(hybrid_history['val_f1'], label='Hybrid Quantum CNN - Val')\n",
    "    axes[1, 0].set_title('F1 Score Comparison')\n",
    "    axes[1, 0].set_xlabel('Epochs')\n",
    "    axes[1, 0].set_ylabel('F1 Score')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Prediction distribution\n",
    "    simple_pred_counts = Counter(simple_results['all_preds'])\n",
    "    hybrid_pred_counts = Counter(hybrid_results['all_preds'])\n",
    "    true_label_counts = Counter(simple_results['all_labels'])\n",
    "    \n",
    "    simple_counts = [simple_pred_counts.get(i, 0) for i in range(len(class_names))]\n",
    "    hybrid_counts = [hybrid_pred_counts.get(i, 0) for i in range(len(class_names))]\n",
    "    true_counts = [true_label_counts.get(i, 0) for i in range(len(class_names))]\n",
    "    \n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    axes[1, 1].bar(x - width, true_counts, width, label='True Distribution')\n",
    "    axes[1, 1].bar(x, simple_counts, width, label='Simple CNN')\n",
    "    axes[1, 1].bar(x + width, hybrid_counts, width, label='Hybrid Quantum CNN')\n",
    "    axes[1, 1].set_title('Prediction Distribution')\n",
    "    axes[1, 1].set_xticks(x)\n",
    "    axes[1, 1].set_xticklabels(class_names)\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison_training.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Compare test results\n",
    "    comparison = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "        'Simple CNN': [simple_results['accuracy'], simple_results['precision'], \n",
    "                       simple_results['recall'], simple_results['f1']],\n",
    "        'Hybrid Quantum CNN': [hybrid_results['accuracy'], hybrid_results['precision'], \n",
    "                               hybrid_results['recall'], hybrid_results['f1']]\n",
    "    })\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = comparison.plot(x='Metric', y=['Simple CNN', 'Hybrid Quantum CNN'], \n",
    "                         kind='bar', figsize=(10, 6))\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Add values on bars\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.4f')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison_metrics.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Compare per-class F1 scores\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, simple_results['per_class_f1'], width, label='Simple CNN')\n",
    "    plt.bar(x + width/2, hybrid_results['per_class_f1'], width, label='Hybrid Quantum CNN')\n",
    "    \n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score by Class')\n",
    "    plt.xticks(x, class_names)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('f1_score_by_class.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Print detailed comparison\n",
    "    print(\"\\nModel Comparison Summary:\")\n",
    "    print(comparison.to_string(index=False))\n",
    "    \n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(base_path, use_balanced_sampler=True):\n",
    "    metadata_path = os.path.join(base_path, 'HAM10000_metadata.csv')\n",
    "    image_dir_1 = os.path.join(base_path, 'HAM10000_images_part_1')\n",
    "    image_dir_2 = os.path.join(base_path, 'HAM10000_images_part_2')\n",
    "    \n",
    "    # Load metadata\n",
    "    print(\"Loading metadata...\")\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "    \n",
    "    # Create label mapping\n",
    "    lesion_type_dict = {\n",
    "        'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3,\n",
    "        'akiec': 4, 'vasc': 5, 'df': 6\n",
    "    }\n",
    "    metadata['label'] = metadata['dx'].map(lesion_type_dict)\n",
    "    \n",
    "    # Collect valid image paths and labels\n",
    "    print(\"Processing image paths...\")\n",
    "    valid_image_paths = []\n",
    "    valid_labels = []\n",
    "    for _, row in tqdm(metadata.iterrows(), total=len(metadata), desc='Processing image paths'):\n",
    "        image_id = row['image_id']\n",
    "        label = row['label']\n",
    "        image_path_1 = os.path.join(image_dir_1, image_id + '.jpg')\n",
    "        image_path_2 = os.path.join(image_dir_2, image_id + '.jpg')\n",
    "        if os.path.exists(image_path_1):\n",
    "            valid_image_paths.append(image_path_1)\n",
    "            valid_labels.append(label)\n",
    "        elif os.path.exists(image_path_2):\n",
    "            valid_image_paths.append(image_path_2)\n",
    "            valid_labels.append(label)\n",
    "    \n",
    "    print(f\"Found {len(valid_image_paths)} valid images\")\n",
    "    \n",
    "    # Print class distribution\n",
    "    label_counts = Counter(valid_labels)\n",
    "    print(\"Class distribution:\")\n",
    "    for label, count in sorted(label_counts.items()):\n",
    "        class_name = list(lesion_type_dict.keys())[list(lesion_type_dict.values()).index(label)]\n",
    "        print(f\"{class_name} (class {label}): {count} images ({count/len(valid_labels)*100:.2f}%)\")\n",
    "    \n",
    "    # Calculate class weights for loss function\n",
    "    class_counts = np.bincount(valid_labels)\n",
    "    n_samples = len(valid_labels)\n",
    "    n_classes = len(np.unique(valid_labels))\n",
    "    class_weights = n_samples / (n_classes * class_counts)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    \n",
    "    # Split dataset\n",
    "    print(\"Splitting dataset...\")\n",
    "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "        valid_image_paths, valid_labels, test_size=0.2, random_state=42, stratify=valid_labels\n",
    "    )\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        train_paths, train_labels, test_size=0.15, random_state=42, stratify=train_labels\n",
    "    )\n",
    "    \n",
    "    print(f\"Train set: {len(train_paths)} images\")\n",
    "    print(f\"Validation set: {len(val_paths)} images\")\n",
    "    print(f\"Test set: {len(test_paths)} images\")\n",
    "    \n",
    "    # Get transforms\n",
    "    train_transform, val_transform = get_optimized_transforms()\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Creating datasets...\")\n",
    "    train_dataset = HAM10000Dataset(train_paths, train_labels, transform=train_transform)\n",
    "    val_dataset = HAM10000Dataset(val_paths, val_labels, transform=val_transform)\n",
    "    test_dataset = HAM10000Dataset(test_paths, test_labels, transform=val_transform)\n",
    "    \n",
    "    # Create balanced sampler for training if requested\n",
    "    if use_balanced_sampler:\n",
    "        print(\"Creating weighted random sampler for balanced training...\")\n",
    "        train_labels_tensor = torch.tensor(train_labels)\n",
    "        class_sample_count = torch.tensor(\n",
    "            [(train_labels_tensor == t).sum() for t in torch.unique(train_labels_tensor, sorted=True)]\n",
    "        )\n",
    "        weight = 1. / class_sample_count.float()\n",
    "        samples_weight = torch.tensor([weight[t] for t in train_labels_tensor])\n",
    "        sampler = torch.utils.data.WeightedRandomSampler(\n",
    "            samples_weight, len(samples_weight), replacement=True\n",
    "        )\n",
    "        train_loader = DataLoader(train_dataset, batch_size=16, sampler=sampler, num_workers=0)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=16, sampler=sampler, num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "    else:\n",
    "        # Create regular data loaders if not using balanced sampler\n",
    "        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, class_weights\n",
    "\n",
    "def main():\n",
    "    # Path to dataset\n",
    "    base_path = '/kaggle/input/skin-cancer-mnist-ham10000'  # Adjust as needed\n",
    "    \n",
    "    # Prepare dataset\n",
    "    print(\"Preparing dataset...\")\n",
    "    train_loader, val_loader, test_loader, class_weights = prepare_dataset(base_path, use_balanced_sampler=True)\n",
    "    \n",
    "    # Send class weights to device\n",
    "    class_weights = class_weights.to(device)\n",
    "    \n",
    "    # Initialize models\n",
    "    print(\"Initializing models...\")\n",
    "    simple_model = SimpleCNN(num_classes=7).to(device)\n",
    "    hybrid_model = HybridQuantumCNN(n_qubits=6, n_qlayers=2, num_classes=7).to(device)\n",
    "    \n",
    "    # Define loss function with class weights for handling imbalance\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    # Define optimizers with weight decay for regularization\n",
    "    simple_optimizer = optim.AdamW(simple_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    hybrid_optimizer = optim.AdamW(hybrid_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    \n",
    "    # Learning rate schedulers\n",
    "    simple_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        simple_optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    "    )\n",
    "    hybrid_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        hybrid_optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate simple CNN\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Training Simple CNN...\")\n",
    "    simple_model, simple_history = train_model(\n",
    "        simple_model, train_loader, val_loader, criterion, simple_optimizer, simple_scheduler,\n",
    "        num_epochs=20, model_name=\"simple_cnn\", patience=7, clip_value=1.0\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Evaluating Simple CNN...\")\n",
    "    simple_results = evaluate_model(simple_model, test_loader, criterion, model_name=\"simple_cnn\")\n",
    "    \n",
    "    # Train and evaluate hybrid quantum CNN\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Training Hybrid Quantum CNN...\")\n",
    "    hybrid_model, hybrid_history = train_model(\n",
    "        hybrid_model, train_loader, val_loader, criterion, hybrid_optimizer, hybrid_scheduler,\n",
    "        num_epochs=20, model_name=\"hybrid_quantum_cnn\", patience=7, clip_value=1.0\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Evaluating Hybrid Quantum CNN...\")\n",
    "    hybrid_results = evaluate_model(hybrid_model, test_loader, criterion, model_name=\"hybrid_quantum_cnn\")\n",
    "    \n",
    "    # Compare models\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Comparing Models...\")\n",
    "    compare_models(simple_history, hybrid_history, simple_results, hybrid_results)\n",
    "    \n",
    "    # Save models\n",
    "    torch.save(simple_model.state_dict(), \"simple_cnn_final.pth\")\n",
    "    torch.save(hybrid_model.state_dict(), \"hybrid_quantum_cnn_final.pth\")\n",
    "    \n",
    "    # Save results\n",
    "    with open(\"simple_cnn_results.pkl\", \"wb\") as f:\n",
    "        pickle.dump(simple_results, f)\n",
    "    with open(\"hybrid_quantum_cnn_results.pkl\", \"wb\") as f:\n",
    "        pickle.dump(hybrid_results, f)\n",
    "    \n",
    "    print(\"\\nExperiment completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Add import for pickle\n",
    "    import pickle\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Run experiment\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pennylane as qml\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Dataset class\n",
    "class HAM10000Dataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform if transform else transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image.float().to(device), torch.tensor(label, dtype=torch.long, device=device)\n",
    "\n",
    "# Define transforms with data augmentation\n",
    "def get_optimized_transforms():\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "# Define regular CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Calculate size after pooling operations\n",
    "        # 224 -> 112 -> 56 -> 28\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Define the improved quantum circuit\n",
    "def create_improved_quantum_circuit(n_qubits=4, n_qlayers=3):\n",
    "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "    \n",
    "    @qml.qnode(dev)\n",
    "    def quantum_circuit(inputs, weights):\n",
    "        # More sophisticated input embedding\n",
    "        for i in range(n_qubits):\n",
    "            qml.RY(inputs[i], wires=i)\n",
    "            qml.RZ(inputs[i], wires=i)\n",
    "        \n",
    "        # More complex variational layers\n",
    "        for l in range(n_qlayers):\n",
    "            # Rotation gates\n",
    "            for i in range(n_qubits):\n",
    "                qml.RY(weights[l][i], wires=i)\n",
    "                qml.RZ(weights[l][i+n_qubits], wires=i)\n",
    "            \n",
    "            # Entangling gates with more connectivity\n",
    "            for i in range(n_qubits):\n",
    "                qml.CNOT(wires=[i, (i+1) % n_qubits])\n",
    "                qml.CNOT(wires=[i, (i+2) % n_qubits])\n",
    "            \n",
    "            # Add measurement-based feature map\n",
    "            # Fixed: Changed n_layers to layers parameter\n",
    "            qml.RandomLayers(weights[l][2*n_qubits:], layers=1, wires=range(n_qubits))\n",
    "        \n",
    "        # More expressive readout\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "    \n",
    "    return quantum_circuit\n",
    "\n",
    "# Define hybrid quantum-classical model\n",
    "class ImprovedHybridQuantumCNN(nn.Module):\n",
    "    def __init__(self, n_qubits=4, n_qlayers=3, num_classes=7):\n",
    "        super(ImprovedHybridQuantumCNN, self).__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_qlayers = n_qlayers\n",
    "        \n",
    "        # Enhanced classical feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Fully connected to reduce dimensions\n",
    "        self.fc_reduce = nn.Linear(128 * 28 * 28, n_qubits)\n",
    "        \n",
    "        # Quantum circuit\n",
    "        self.quantum_circuit = create_improved_quantum_circuit(n_qubits, n_qlayers)\n",
    "        \n",
    "        # Initialize quantum weights with more parameters\n",
    "        weight_shapes = {\n",
    "            \"weights\": (n_qlayers, 3*n_qubits)  # More weights for complexity\n",
    "        }\n",
    "        self.qlayer = qml.qnn.TorchLayer(self.quantum_circuit, weight_shapes)\n",
    "        \n",
    "        # Classical output layers with dropout\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_qubits, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Classical feature extraction\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Reduce to quantum input dimension\n",
    "        x = self.fc_reduce(x)\n",
    "        x = torch.tanh(x) * np.pi  # Scale to [-π, π] for rotation gates\n",
    "        \n",
    "        # Process each example through the quantum circuit\n",
    "        q_out = torch.stack([self.qlayer(x[i]) for i in range(x.shape[0])])\n",
    "        \n",
    "        # Final classification\n",
    "        x = self.classifier(q_out)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10, model_name=\"model\"):\n",
    "    best_val_acc = 0.0\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    print(f\"Starting training {model_name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        train_loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for inputs, labels in train_loop:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_loop.set_postfix(loss=loss.item(), acc=correct/total)\n",
    "        \n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = correct / total\n",
    "        \n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_loop = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')\n",
    "            for inputs, labels in val_loop:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Update progress bar\n",
    "                val_loop.set_postfix(loss=loss.item(), acc=correct/total)\n",
    "        \n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = correct / total\n",
    "        \n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        \n",
    "        # Step the scheduler\n",
    "        if scheduler:\n",
    "            scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}, '\n",
    "              f'Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            torch.save(model.state_dict(), f'{model_name}_best.pth')\n",
    "            print(f'Saved new best model with validation accuracy: {best_val_acc:.4f}')\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f'Training completed in {total_time/60:.2f} minutes')\n",
    "    print(f'Best validation accuracy: {best_val_acc:.4f}')\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_loader, criterion, model_name=\"model\"):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=f'Evaluating {model_name}'):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Per-class metrics\n",
    "    class_names = ['nv', 'mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df']\n",
    "    per_class_precision = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "    per_class_recall = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "    per_class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "    \n",
    "    # Print results\n",
    "    print(f'\\nTest Results for {model_name}:')\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    \n",
    "    print('\\nPer-class metrics:')\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f'{class_name}: Precision={per_class_precision[i]:.4f}, Recall={per_class_recall[i]:.4f}, F1={per_class_f1[i]:.4f}')\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name}_confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    results = {\n",
    "        'loss': test_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'per_class_precision': per_class_precision,\n",
    "        'per_class_recall': per_class_recall,\n",
    "        'per_class_f1': per_class_f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to compare models\n",
    "def compare_models(simple_history, hybrid_history, simple_results, hybrid_results):\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(simple_history['train_loss'], label='Simple CNN - Train')\n",
    "    plt.plot(simple_history['val_loss'], label='Simple CNN - Val')\n",
    "    plt.plot(hybrid_history['train_loss'], label='Hybrid Quantum CNN - Train')\n",
    "    plt.plot(hybrid_history['val_loss'], label='Hybrid Quantum CNN - Val')\n",
    "    plt.title('Loss Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(simple_history['train_acc'], label='Simple CNN - Train')\n",
    "    plt.plot(simple_history['val_acc'], label='Simple CNN - Val')\n",
    "    plt.plot(hybrid_history['train_acc'], label='Hybrid Quantum CNN - Train')\n",
    "    plt.plot(hybrid_history['val_acc'], label='Hybrid Quantum CNN - Val')\n",
    "    plt.title('Accuracy Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison_training.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Compare test results\n",
    "    comparison = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "        'Simple CNN': [simple_results['accuracy'], simple_results['precision'], simple_results['recall'], simple_results['f1']],\n",
    "        'Hybrid Quantum CNN': [hybrid_results['accuracy'], hybrid_results['precision'], hybrid_results['recall'], hybrid_results['f1']]\n",
    "    })\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    comparison.plot(x='Metric', y=['Simple CNN', 'Hybrid Quantum CNN'], kind='bar', figsize=(10, 6))\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1)\n",
    "    for i, v in enumerate(comparison['Simple CNN']):\n",
    "        plt.text(i-0.1, v+0.01, f\"{v:.4f}\", ha='center')\n",
    "    for i, v in enumerate(comparison['Hybrid Quantum CNN']):\n",
    "        plt.text(i+0.1, v+0.01, f\"{v:.4f}\", ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison_metrics.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # F1 score comparison per class\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(simple_results['per_class_f1']))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, simple_results['per_class_f1'], width, label='Simple CNN')\n",
    "    plt.bar(x + width/2, hybrid_results['per_class_f1'], width, label='Hybrid Quantum CNN')\n",
    "    \n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score by Class')\n",
    "    plt.xticks(x, ['nv', 'mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df'])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('f1_score_by_class.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Print detailed comparison\n",
    "    print(\"\\nModel Comparison Summary:\")\n",
    "    print(comparison.to_string(index=False))\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "# Function to prepare dataset\n",
    "def prepare_dataset(base_path):\n",
    "    metadata_path = os.path.join(base_path, 'HAM10000_metadata.csv')\n",
    "    image_dir_1 = os.path.join(base_path, 'HAM10000_images_part_1')\n",
    "    image_dir_2 = os.path.join(base_path, 'HAM10000_images_part_2')\n",
    "    \n",
    "    # Load metadata\n",
    "    print(\"Loading metadata...\")\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "    \n",
    "    # Create label mapping\n",
    "    lesion_type_dict = {\n",
    "        'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3,\n",
    "        'akiec': 4, 'vasc': 5, 'df': 6\n",
    "    }\n",
    "    metadata['label'] = metadata['dx'].map(lesion_type_dict)\n",
    "    \n",
    "    # Collect valid image paths and labels\n",
    "    print(\"Processing image paths...\")\n",
    "    valid_image_paths = []\n",
    "    valid_labels = []\n",
    "    for _, row in tqdm(metadata.iterrows(), total=len(metadata), desc='Processing image paths'):\n",
    "        image_id = row['image_id']\n",
    "        label = row['label']\n",
    "        image_path_1 = os.path.join(image_dir_1, image_id + '.jpg')\n",
    "        image_path_2 = os.path.join(image_dir_2, image_id + '.jpg')\n",
    "        if os.path.exists(image_path_1):\n",
    "            valid_image_paths.append(image_path_1)\n",
    "            valid_labels.append(label)\n",
    "        elif os.path.exists(image_path_2):\n",
    "            valid_image_paths.append(image_path_2)\n",
    "            valid_labels.append(label)\n",
    "    \n",
    "    print(f\"Found {len(valid_image_paths)} valid images\")\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_counts = pd.Series(valid_labels).value_counts().sort_index()\n",
    "    class_weights = 1.0 / class_counts  # Inverse of class frequencies\n",
    "    class_weights = torch.tensor(class_weights.values, dtype=torch.float32)\n",
    "    \n",
    "    # Split dataset\n",
    "    print(\"Splitting dataset...\")\n",
    "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "        valid_image_paths, valid_labels, test_size=0.2, random_state=42, stratify=valid_labels\n",
    "    )\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        train_paths, train_labels, test_size=0.15, random_state=42, stratify=train_labels\n",
    "    )\n",
    "    \n",
    "    print(f\"Train set: {len(train_paths)} images\")\n",
    "    print(f\"Validation set: {len(val_paths)} images\")\n",
    "    print(f\"Test set: {len(test_paths)} images\")\n",
    "    \n",
    "    # Get transforms\n",
    "    train_transform, val_transform = get_optimized_transforms()\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Creating datasets...\")\n",
    "    train_dataset = HAM10000Dataset(train_paths, train_labels, transform=train_transform)\n",
    "    val_dataset = HAM10000Dataset(val_paths, val_labels, transform=val_transform)\n",
    "    test_dataset = HAM10000Dataset(test_paths, test_labels, transform=val_transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    print(\"Creating data loaders...\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, class_weights\n",
    "\n",
    "# Main function to run experiments\n",
    "def run_experiments(train_loader, val_loader, test_loader, class_weights, epochs=10):\n",
    "    # Define models\n",
    "    simple_cnn = SimpleCNN(num_classes=7).to(device)\n",
    "    hybrid_qcnn = ImprovedHybridQuantumCNN(n_qubits=4, n_qlayers=3, num_classes=7).to(device)\n",
    "    \n",
    "    # Define loss function with class weights\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    \n",
    "    # Optimizers with different learning rates\n",
    "    simple_optimizer = optim.Adam(simple_cnn.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    hybrid_optimizer = optim.Adam(hybrid_qcnn.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "    \n",
    "    # Schedulers\n",
    "    simple_scheduler = optim.lr_scheduler.ReduceLROnPlateau(simple_optimizer, mode='min', factor=0.5, patience=3)\n",
    "    hybrid_scheduler = optim.lr_scheduler.ReduceLROnPlateau(hybrid_optimizer, mode='min', factor=0.5, patience=3)\n",
    "    \n",
    "    # Train the models\n",
    "    simple_cnn, simple_history = train_model(\n",
    "        simple_cnn, train_loader, val_loader, criterion, \n",
    "        simple_optimizer, simple_scheduler, num_epochs=epochs, \n",
    "        model_name=\"simple_cnn\"\n",
    "    )\n",
    "    \n",
    "    hybrid_qcnn, hybrid_history = train_model(\n",
    "        hybrid_qcnn, train_loader, val_loader, criterion, \n",
    "        hybrid_optimizer, hybrid_scheduler, num_epochs=epochs,\n",
    "        model_name=\"hybrid_qcnn\"\n",
    "    )\n",
    "    \n",
    "    # Evaluate the models\n",
    "    simple_results = evaluate_model(simple_cnn, test_loader, criterion, model_name=\"Simple CNN\")\n",
    "    hybrid_results = evaluate_model(hybrid_qcnn, test_loader, criterion, model_name=\"Hybrid Quantum CNN\")\n",
    "    \n",
    "    # Compare the models\n",
    "    comparison = compare_models(simple_history, hybrid_history, simple_results, hybrid_results)\n",
    "    \n",
    "    return simple_cnn, hybrid_qcnn, comparison\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Set base path (modify this to your dataset location)\n",
    "    base_path = '/kaggle/input/skin-cancer-mnist-ham10000'\n",
    "    \n",
    "    # Prepare dataset\n",
    "    train_loader, val_loader, test_loader, class_weights = prepare_dataset(base_path)\n",
    "    \n",
    "    # Set number of epochs\n",
    "    NUM_EPOCHS = 10  # Adjust based on your computational resources\n",
    "    \n",
    "    # Run the experiments\n",
    "    simple_model, hybrid_model, results = run_experiments(\n",
    "        train_loader, val_loader, test_loader, class_weights, epochs=NUM_EPOCHS\n",
    "    )\n",
    "    \n",
    "    print(\"Experiment completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T16:45:20.005071Z",
     "iopub.status.busy": "2025-02-15T16:45:20.004746Z",
     "iopub.status.idle": "2025-02-15T20:48:04.296565Z",
     "shell.execute_reply": "2025-02-15T20:48:04.295708Z",
     "shell.execute_reply.started": "2025-02-15T16:45:20.005046Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Modified Quantum Hybrid Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/20: 100%|██████████| 501/501 [09:59<00:00,  1.20s/it]\n",
      "Validating Epoch 1/20: 100%|██████████| 126/126 [02:07<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc: 12.17%, Val Acc: 11.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/20: 100%|██████████| 501/501 [10:01<00:00,  1.20s/it]\n",
      "Validating Epoch 2/20: 100%|██████████| 126/126 [02:09<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Acc: 12.33%, Val Acc: 17.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/20: 100%|██████████| 501/501 [09:58<00:00,  1.20s/it]\n",
      "Validating Epoch 3/20: 100%|██████████| 126/126 [02:06<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Acc: 13.49%, Val Acc: 19.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/20: 100%|██████████| 501/501 [09:53<00:00,  1.18s/it]\n",
      "Validating Epoch 4/20: 100%|██████████| 126/126 [02:06<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Acc: 16.59%, Val Acc: 27.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/20: 100%|██████████| 501/501 [09:53<00:00,  1.19s/it]\n",
      "Validating Epoch 5/20: 100%|██████████| 126/126 [02:07<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Acc: 25.15%, Val Acc: 38.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/20: 100%|██████████| 501/501 [09:59<00:00,  1.20s/it]\n",
      "Validating Epoch 6/20: 100%|██████████| 126/126 [02:07<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Acc: 37.79%, Val Acc: 58.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/20: 100%|██████████| 501/501 [10:01<00:00,  1.20s/it]\n",
      "Validating Epoch 7/20: 100%|██████████| 126/126 [02:09<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Acc: 51.05%, Val Acc: 64.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/20: 100%|██████████| 501/501 [10:04<00:00,  1.21s/it]\n",
      "Validating Epoch 8/20: 100%|██████████| 126/126 [02:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Acc: 60.33%, Val Acc: 65.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/20: 100%|██████████| 501/501 [10:03<00:00,  1.20s/it]\n",
      "Validating Epoch 9/20: 100%|██████████| 126/126 [02:07<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Acc: 64.43%, Val Acc: 65.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/20: 100%|██████████| 501/501 [10:05<00:00,  1.21s/it]\n",
      "Validating Epoch 10/20: 100%|██████████| 126/126 [02:07<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Acc: 65.76%, Val Acc: 66.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/20: 100%|██████████| 501/501 [09:58<00:00,  1.19s/it]\n",
      "Validating Epoch 11/20: 100%|██████████| 126/126 [02:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Acc: 66.30%, Val Acc: 65.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/20: 100%|██████████| 501/501 [09:49<00:00,  1.18s/it]\n",
      "Validating Epoch 12/20: 100%|██████████| 126/126 [02:05<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Acc: 66.51%, Val Acc: 66.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/20: 100%|██████████| 501/501 [09:45<00:00,  1.17s/it]\n",
      "Validating Epoch 13/20: 100%|██████████| 126/126 [02:06<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Acc: 66.63%, Val Acc: 66.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/20: 100%|██████████| 501/501 [09:54<00:00,  1.19s/it]\n",
      "Validating Epoch 14/20: 100%|██████████| 126/126 [02:06<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Acc: 66.59%, Val Acc: 66.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/20: 100%|██████████| 501/501 [09:54<00:00,  1.19s/it]\n",
      "Validating Epoch 15/20: 100%|██████████| 126/126 [02:07<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Acc: 66.65%, Val Acc: 66.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/20: 100%|██████████| 501/501 [09:47<00:00,  1.17s/it]\n",
      "Validating Epoch 16/20: 100%|██████████| 126/126 [02:06<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Acc: 66.75%, Val Acc: 66.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/20: 100%|██████████| 501/501 [09:56<00:00,  1.19s/it]\n",
      "Validating Epoch 17/20: 100%|██████████| 126/126 [02:07<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Acc: 66.76%, Val Acc: 66.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/20: 100%|██████████| 501/501 [09:57<00:00,  1.19s/it]\n",
      "Validating Epoch 18/20: 100%|██████████| 126/126 [02:07<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Acc: 66.65%, Val Acc: 66.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/20: 100%|██████████| 501/501 [09:54<00:00,  1.19s/it]\n",
      "Validating Epoch 19/20: 100%|██████████| 126/126 [02:06<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Acc: 66.65%, Val Acc: 66.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/20: 100%|██████████| 501/501 [09:52<00:00,  1.18s/it]\n",
      "Validating Epoch 20/20: 100%|██████████| 126/126 [02:06<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Acc: 66.76%, Val Acc: 66.65%\n",
      "\n",
      "Final Results:\n",
      "Modified Quantum Model Best Validation Accuracy: 66.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class HAM10000Dataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform if transform else transforms.ToTensor()\n",
    "        \n",
    "        self.images = []\n",
    "        for path in image_paths:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            self.images.append(img.copy())\n",
    "            img.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image.to(device), torch.tensor(label, dtype=torch.long, device=device)\n",
    "\n",
    "def get_transforms():\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "class ImprovedQuantumCircuit(nn.Module):\n",
    "    def __init__(self, n_qubits=8, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        self.dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "        \n",
    "        @qml.qnode(self.dev, interface=\"torch\")\n",
    "        def quantum_circuit(inputs, weights):\n",
    "            # AngleEmbedding instead of AmplitudeEmbedding\n",
    "            qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "            \n",
    "            # Multiple layers of parameterized quantum gates\n",
    "            for l in range(n_layers):\n",
    "                # Rotation layer\n",
    "                for i in range(n_qubits):\n",
    "                    qml.RX(weights[l*3*n_qubits + i], wires=i)\n",
    "                    qml.RY(weights[l*3*n_qubits + n_qubits + i], wires=i)\n",
    "                    qml.RZ(weights[l*3*n_qubits + 2*n_qubits + i], wires=i)\n",
    "                \n",
    "                # Entangling layer - circular pattern\n",
    "                for i in range(n_qubits):\n",
    "                    qml.CNOT(wires=[i, (i + 1) % n_qubits])\n",
    "                \n",
    "                # Additional entangling connections\n",
    "                if l % 2 == 0:  # Alternate layer connections\n",
    "                    for i in range(0, n_qubits, 2):\n",
    "                        qml.CNOT(wires=[i, (i + 2) % n_qubits])\n",
    "            \n",
    "            # Measurement layer\n",
    "            return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "        \n",
    "        self.quantum_circuit = quantum_circuit\n",
    "        self.weights = nn.Parameter(torch.randn(3 * n_qubits * n_layers, device=device) * 0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        q_out = self.quantum_circuit(x, self.weights)\n",
    "        return torch.tensor(q_out, dtype=torch.float32, device=device)\n",
    "\n",
    "class ModifiedQuantumHybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Custom CNN backbone instead of ResNet50\n",
    "        self.backbone = nn.Sequential(\n",
    "            # First convolutional block\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            \n",
    "            # Second convolutional block\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Third convolutional block\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Fourth convolutional block\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Fifth convolutional block\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Global average pooling\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        # Feature reduction pathway\n",
    "        self.feature_reduction = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 8)\n",
    "        )\n",
    "        \n",
    "        # Quantum circuit with 8 qubits and 3 layers\n",
    "        self.quantum_layer = ImprovedQuantumCircuit(n_qubits=8, n_layers=3)\n",
    "        \n",
    "        # Enhanced classical post-processing\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(8, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, num_classes)\n",
    "        ).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        # Extract features using the backbone\n",
    "        features = self.backbone(x)\n",
    "        # Flatten the features\n",
    "        features = features.view(features.size(0), -1)\n",
    "        # Apply feature reduction\n",
    "        features = self.feature_reduction(features)\n",
    "        # Apply quantum processing\n",
    "        quantum_features = torch.stack([self.quantum_layer(features[i]) for i in range(features.shape[0])])\n",
    "        # Final classification\n",
    "        return self.classifier(quantum_features)\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, device, epochs=20):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Separate learning rates for classical and quantum parts\n",
    "    classical_params = list(model.backbone.parameters()) + list(model.feature_reduction.parameters()) + list(model.classifier.parameters())\n",
    "    quantum_params = list(model.quantum_layer.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': classical_params, 'lr': 0.0001, 'weight_decay': 0.01},\n",
    "        {'params': quantum_params, 'lr': 0.01, 'weight_decay': 0.001}\n",
    "    ])\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=[0.0001, 0.01],\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=len(train_loader)\n",
    "    )\n",
    "    \n",
    "    model.to(device)\n",
    "    best_val_acc = 0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0, 0, 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Training Epoch {epoch+1}/{epochs}'):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f'Validating Epoch {epoch+1}/{epochs}'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['val_loss'].append(val_loss / len(val_loader))\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_modified_quantum_hybrid_model.pth')\n",
    "    \n",
    "    return history\n",
    "\n",
    "def main():\n",
    "    # Set random seeds for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Dataset paths for Kaggle\n",
    "    base_path = '/kaggle/input/skin-cancer-mnist-ham10000'\n",
    "    metadata_path = os.path.join(base_path, 'HAM10000_metadata.csv')\n",
    "    image_dir_1 = os.path.join(base_path, 'HAM10000_images_part_1')\n",
    "    image_dir_2 = os.path.join(base_path, 'HAM10000_images_part_2')\n",
    "    \n",
    "    # Load metadata\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "    \n",
    "    # Create label mapping\n",
    "    lesion_type_dict = {\n",
    "        'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3,\n",
    "        'akiec': 4, 'vasc': 5, 'df': 6\n",
    "    }\n",
    "    metadata['label'] = metadata['dx'].map(lesion_type_dict)\n",
    "    \n",
    "    # Collect valid image paths and labels\n",
    "    valid_image_paths = []\n",
    "    valid_labels = []\n",
    "    \n",
    "    for _, row in metadata.iterrows():\n",
    "        image_id = row['image_id']\n",
    "        label = row['label']\n",
    "        \n",
    "        image_path_1 = os.path.join(image_dir_1, image_id + '.jpg')\n",
    "        image_path_2 = os.path.join(image_dir_2, image_id + '.jpg')\n",
    "        \n",
    "        if os.path.exists(image_path_1):\n",
    "            valid_image_paths.append(image_path_1)\n",
    "            valid_labels.append(label)\n",
    "        elif os.path.exists(image_path_2):\n",
    "            valid_image_paths.append(image_path_2)\n",
    "            valid_labels.append(label)\n",
    "    \n",
    "    # Split data\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        valid_image_paths, valid_labels, test_size=0.2, random_state=42, stratify=valid_labels\n",
    "    )\n",
    "    \n",
    "    # Get transforms\n",
    "    train_transform, val_transform = get_transforms()\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = HAM10000Dataset(train_paths, train_labels, transform=train_transform)\n",
    "    val_dataset = HAM10000Dataset(val_paths, val_labels, transform=val_transform)\n",
    "    \n",
    "    # Create dataloaders with increased batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Train and evaluate modified quantum model\n",
    "    print(\"\\nTraining Modified Quantum Hybrid Model...\")\n",
    "    quantum_model = ModifiedQuantumHybridModel().to(device)\n",
    "    quantum_history = train_and_evaluate(quantum_model, train_loader, val_loader, device, epochs=20)\n",
    "    \n",
    "    # Plot and save results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(quantum_history['train_acc'], label='Train')\n",
    "    plt.plot(quantum_history['val_acc'], label='Validation')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(quantum_history['train_loss'], label='Train')\n",
    "    plt.plot(quantum_history['val_loss'], label='Validation')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('modified_quantum_model_performance.png')\n",
    "    \n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"Modified Quantum Model Best Validation Accuracy: {max(quantum_history['val_acc']):.2f}%\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
